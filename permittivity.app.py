# -*- coding: utf-8 -*-
"""Permittivity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HWjripWcUGbLUE7XAOWREco6nTfSgE44
"""

import pandas as pd
df = pd.read_excel("/content/PVC relative.P.xlsx")
df

df = df.drop(['S.No.','Akzocode','Color Type','Project'], axis =1)
#df = df.drop(['Relative Permittivity',' 'Reflection (top) Calc in db'], axis =1)

df

df.dtypes

X = df.drop("RP BMW substrate", axis=1)
y = df["RP BMW substrate"]

from sklearn.preprocessing import LabelEncoder
for col in X.select_dtypes(include='object').columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

import xgboost as xgb

model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # manually take sqrt
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.3f}")
print(f"RÂ²: {r2:.3f}")

import matplotlib.pyplot as plt
import xgboost as xgb

# Plot feature importance
xgb.plot_importance(model, importance_type='weight')
plt.show()

xgb.plot_importance(model, importance_type='gain')
plt.show()

model = xgb.XGBRegressor(
    n_estimators=1000,  # more trees
    learning_rate=0.05,
    max_depth=8,       # deeper trees
    subsample=0.70,
    colsample_bytree=0.70,
    reg_lambda=0.50,     # less penalty
    random_state=42
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # manually take sqrt
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.3f}")
print(f"RÂ²: {r2:.3f}")

xgb.plot_importance(model, importance_type='weight')
plt.show()

from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import pandas as pd

# Assuming your model is already trained:
# model = xgb.XGBRegressor(...).fit(X_train, y_train)

# Run permutation importance on the test set
perm_importance = permutation_importance(
    model, X_test, y_test, n_repeats=10, random_state=42, scoring='r2'
)

# Put results in a DataFrame
perm_df = pd.DataFrame({
    "feature": X_test.columns,
    "importance_mean": perm_importance.importances_mean,
    "importance_std": perm_importance.importances_std
}).sort_values(by="importance_mean", ascending=False)

print(perm_df)

# Plot top features
plt.figure(figsize=(8,6))
plt.barh(perm_df["feature"], perm_df["importance_mean"])
plt.gca().invert_yaxis()
plt.xlabel("Permutation Importance (Decrease in RÂ²)")
plt.title("Permutation Feature Importance")
plt.show()

import streamlit as st
import pandas as pd
import joblib

# Load trained model (make sure xgb_model.pkl is in your repo)
model = joblib.load("xgb_model.pkl")

st.title("ðŸ“Š Permittivity Prediction Tool")

st.write("Upload an Excel file with new data and get predictions.")

# File upload
uploaded_file = st.file_uploader("Upload Excel file", type=["xlsx"])

if uploaded_file:
    # Read data
    new_data = pd.read_excel(uploaded_file)

    st.write("### Preview of Uploaded Data")
    st.write(new_data.head())

    # Predict
    try:
        predictions = model.predict(new_data)
        new_data["Predictions"] = predictions

        # Show results
        st.write("### Predictions")
        st.write(new_data)

        # Download option
        output_file = "predictions.xlsx"
        new_data.to_excel(output_file, index=False)
        with open(output_file, "rb") as f:
            st.download_button("ðŸ“¥ Download Predictions", f, file_name="predictions.xlsx")
    except Exception as e:
        st.error(f"Error while predicting: {e}")









